training$Superplasticizer
training$Superplasticizer<0
sum(training$Superplasticizer<0)
preProc<-preProcess(training,method='pca',pcaComp=2)
trainPC<-predict(preProc,training)
training$Superplasticizer
hist(training$Superplasticizer)
hist(log2(training$Superplasticizer)
)
log(training$Superplasticizer +1)
log(training$Superplasticizer)
log(training$Superplasticizer+1)
hist(log(training$Superplasticizer+1))
source("http://bioconductor.org/biocLite.R")
biocLite()
biocLite(edgeR)
biocLite('edgeR')
library(edgeR)
biocLite('limma')
biocLite('edgeR')
library(edgeR)
biocLite('ebayseq')
biocLite('bayseq')
2
biocLite('baySeq')
library(knitr)
---
title: "Regression model Project"
data(mtcars)
str(mtcars)
mtcars$am
mtcars$am<-as.factor(mtcars$am)
str(mtcars)
factor(mtcars$am)
level(mtcars$am)<-c('manual','auto')
levels(mtcars$am)<-c('manual','auto')
mtcars$am
source('~/.active-rstudio-document', echo=TRUE)
library(knitr)
library(maps)
install.packages('maps')
?by
by(mtcars$mpg,mtcars$am,t.test)
t.test(mtcars$mpg,mtcars$am)
by(mtcars$mpg,mtcars$am,t.test,simplify=0)
t.test(mtcars$mpg[mpg$am=='auto'],mtcars$mpg[mpg$am='manual'])
t.test(mtcars$mpg[mpg$am=='auto'],mtcars$mpg[mpg$am=='manual'])
mtcars$mpg[mpg$am=='auto']
t.test(mtcars$mpg[mtcars$am=='auto'],mtcars$mpg[mtcars$am='manual'])
t.test(mtcars$mpg[mtcars$am=='auto'],mtcars$mpg[mtcars$am=='manual'])
t<-t.test(mtcars$mpg[mtcars$am=='auto'],mtcars$mpg[mtcars$am=='manual'])
t$p.value
ttest<-t.test(mtcars$mpg[mtcars$am=='auto'],mtcars$mpg[mtcars$am=='manual'])
ttest
summary(mt$mpg)
summary(mtcars$mpg)
?summary
t<-summary(mtcars$mpg)
t[3]
t[4]
summary(mtcars$mpg[mtcars$am=='auto'])
summary(mtcars$mpg[mtcars$am=='auto'])-summary(mtcars$mpg[mtcars$am=='manual'])
?mtcars
auto_vs_weight<-lm(mtcars$mpg~mtcars$wt)
auto_vs_weight$coefficient
manual_vs_weight$coefficient
ggplot(mtcars,aes(am,colour=am))+geom_barplot()+facet_wrap(~cyl)
ggplot(mtcars,aes(am,mpg,colour=am))+geom_boxplot()+facet_wrap(~cyl)
ggplot(mtcars,aes(cyl,mpg,colour=am))+geom_point()
?mtcars
manual_vs_weight<-lm(mtcars$mpg[mtcars$am=='manual']~mtcars$wt[mtcars$am=='manual'])
plot(manual_vs_weight)
plot(mtcars$wt[mtcars$am=='auto'],resid(auto_vs_weight))
resid(auto_vs_weight)
mtcars$wt[mtcars$am=='auto']
auto_vs_weight<-lm(mtcars$mpg[mtcars$am=='auto']~mtcars$wt[mtcars$am=='auto'])
plot(mtcars$wt[mtcars$am=='auto'],resid(auto_vs_weight))
resid(auto_vs_weight)
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
install.packages('ISLR')
library(ISLR)
data(Wage)
?Wage
head(Wage)
names(Wage)
head(row.names(Wage))
?createDataPartition
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
dim(training)
dim(testing)
featurePlot(x=training[,c('age','education')],y=training$wage,plot='pairs')
?featurepl
?featurePlot
?iris
?train
names(getModelInfo())
library(rattle)
install.packages('rattle')
training<-read.csv('pml-training.csv')
testing<-read.csv('pml-testing.csv')
dim(training)
names(training)
head(training,1)
dim(testing)
library(kernlab)
names(training)
is.na(training)
sapply(training,function(x) sum(is.na(x)))
str(training$X)
names(training)
?grep
grep('.*dumbbell.*',names(training))
names(training)[grep('.*dumbbell.*',names(training))]
mymodel<-train(roll_dumbbell,method='rpart',data=training)
mymodel<-train(roll_dumbbell~,method='rpart',data=training)
mymodel<-train(roll_dumbbell ~ .,method='rpart',data=training)
mymodel<-train(classe ~ grep('.*dumbbell.*',names(training)),method='rpart',data=training)
dumbbell_training<-training[,c(grep('.*dumbbell.*',names(training)),'classe')]
dumbbell_training<-training[,c(grep('.*dumbbell.*',names(training)),'classe')]
dummbell_num<-grep('.*dumbbell.*',names(training))
dumbell_num
dummbell_num<-c(dummbell_num,160)
dummbell_num
mymodel<-(classe~.,method='glm',data=training)
mymodel<-(classe ~ .,method='glm',data=training)
mymodel<-(classe ~ ., method='glm',data=training)
mymodel<-(classe ~ . ,method='glm',data=training)
mymodel<-train(classe ~ . ,method='glm',data=training)
mymodel<-train(classe ~ . ,method='lm',data=training)
mymodel<-train(classe ~ . ,method='rpart',data=training)
training<-read.csv('pml-training.csv')
testing<-read,csv('pml-testing.csv')
testing<-read.csv('pml-testing.csv')
library(caret)
Modelfit<-train(classe~.,method='lm',data=training)
names(training)
Modelfit<-train(classe~.-user_name-X,method='lm',data=training)
Modelfit<-train(classe~.-user_name-X,method='rpart',data=training)
install.packages('e1071')
Modelfit<-train(classe~.-user_name-X,method='rpart',data=training)
plot(Modelfit$finalModel,uniform = TRUE)
predict_data<-predict(Modelfit,newdata=testing)
warning
names(training)
?corre
sapply(training,function(x) cor(x,training$classe))
training$classe
Modelfit
predict(Modelfit,newdata = testing)
sapply(training,function(x) cor(x,as.numeric(training$classe)))
sapply(training,function(x) cor(as.numeric(x),as.numeric(training$classe)))
allcorr<-sapply(training,function(x) cor(as.numeric(x),as.numeric(training$classe)))
allcorr>0.3
sum(allcorr>0.3)
sum(allcorr>0.3,rm.na=1)
sum(allcorr>0.3,na.rm = 1)
good_cor<-allcorr>0.3
allcorr<-0.3
allcorr<-sapply(training,function(x) cor(as.numeric(x),as.numeric(training$classe)))
allcorr<(-0.3)
sum(allcorr<(-0.3),na.rm = 1)
names(training)[good_cor]
good_cor
!is.na(good_cor)
good_cor
Modelfit<-train(classe~pitch_forearm,method='lm',data=training)
Modelfit<-train(as.numeric(classe)~pitch_forearm,method='lm',data=training)
prediction<-predict(Modelfit,newdata = testing)
prediction
confusionMatrix(prediction,training$classe)
confusionMatrix(prediction,as.numerictraining$classe)
confusionMatrix(prediction,as.numeric(training$classe))
confusionMatrix(prediction,as.numeric(testing$classe))
confusionMatrix(prediction,testing$classe)
Modelfit<-train(classe~pitch_forearm,method='rpart',data=training)
prediction<-predict(Modelfit,newdata = testing)
confusionMatrix(prediction,testing$classe)
prediction
testing$classe
names(test)
names(testing)
names(training)[good_cor]
names(training)[good_cor][1]
names(training)[good_cor][2]
names(training)[!is.na(names(training)[good_cor])]
set.seed(12345)
dim(testing)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(prediction)
prediction
source("http://bioconductor.org/biocLite.R")
biocLite("BitSeq")
biocLite("DEGseq")
getwd()
read.csv('getdata-data-ss06hid.csv')
t<-read.csv('getdata-data-ss06hid.csv')
names(t)
strplit(names(t))
strsplit(names(t))
strsplit(names(t)split = 'wgtp')
strsplit(names(t),split = 'wgtp')
s<-read.csv('getdata-data-GDP.csv')
s$GDP
gsub(levels(s$GDP))
gsub(levels(s$GDP),',')
?gsub
gsub(levels(s$GDP),',','')
gsub(',','',levels(s$GDP),)
levels(s$GDP)<-gsub(',','',levels(s$GDP))
mean(as.numeric(as.character(s$GDP)))
names(s)
s$Country
s$Economy
as.character(s$Economy)
grep("^United",as.character(s$Economy))
as.character(s$Economy)
country_name<-as.character(s$Economy)
grep("^United*",country_name
)
country_name[99]
u<-read.csv('getdata-data-EDSTATS_Country.csv')
head(u)
merge(u,s,by.x='CountryCode',by.y=Country)
merge(u,s,by.x='CountryCode',by.y='Country')
merged<-merge(u,s,by.x='CountryCode',by.y='Country')
names(merged)
head(merged)
merged$Special.Notes
as.character(merged$Special.Notes)
special_notes<-as.character(merged$Special.Notes)
grep("^Fiscal year end",special_notes)
special_notes[grep("^Fiscal year end",special_notes)]
special_notes<-special_notes[grep("^Fiscal year end",special_notes)]
strsplit('Fiscal year end: ',special_notes)
strsplit(special_notes,'Fiscal year end: ')
sapply(strsplit(special_notes,'Fiscal year end: '),'[[')[2]
sapply(strsplit(special_notes,'Fiscal year end: '),'[['[2])
sapply(strsplit(special_notes,'Fiscal year end: '),'[[')
?'[['
sapply(strsplit(special_notes,'Fiscal year end: '),function(x) '[['[2])
sapply(strsplit(special_notes,'Fiscal year end: '),function(x) '[['[1])
sapply(strsplit(special_notes,'Fiscal year end: '),function(x) [[x]][2])
sapply(strsplit(special_notes,'Fiscal year end: ')
)
gsub('Fiscal year end: ','',special_notes)
special_notes<-gsub('Fiscal year end: ','',special_notes)
strsplit(' ',special_notes)
strsplit(special_notes,' ')
strsplit(special_notes,' ')[1]
strsplit(special_notes,' ')[1][1]
strsplit(special_notes,' ')[[1]]
strsplit(special_notes,' ')[[1]][1]
sapply(strsplit(special_notes,' '),'[[')
sapply(strsplit(special_notes,' '),FUN = '[[')
sapply(strsplit(special_notes,' '),print)
temp<-strsplit(special_notes,' ')
sapply(temp,'[[')
sapply(temp,print)
special_notes
grep('^June',special_notes)
sum(grep('^June',special_notes))
length(grep('^June',special_notes))
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
substr(sampleTimes,0,4)
year<-substr(sampleTimes,0,4)
sampleTimes
class(sampleTimes)
?Date
?weekdays
weekdays(sampleTimes)
weekdays(sampleTimes)=='Monday'
year=='2012'
year[year=='2012']
weekdays(sampleTimes[year=='2012'])
weekdays(sampleTimes[year=='2012'])=='Monday'
sum(weekdays(sampleTimes[year=='2012'])=='Monday')
special_notes
strsplit(special_notes,' ')
sapply(strsplit(special_notes,' '),function(x){x[1]})
?gsub
str_t
library(stringr)
str_trim(special_notes)
data(spam)
library(krenlab)
library(kernlab)
install.packages('kernlab')
library
library
library(kernlab)
data(spam)
30*.75
70*.47
x*.75+(1-x)*.47=30
x*.75+(1-x)*.47=30
0.47-0.28*x=0.3
x<-read.csv('../DifferentialExpressionTools/Random2/profiled_A1.pro')
head(x)
x<-read.table('../DifferentialExpressionTools/Random2/profiled_A1.pro',sep='\t')
head(x)
sum(x[,6])
str(x)
sum(as.numeric(x[,6]))
read.csv('../DifferentialExpressionTools/count_table_merged.csv')
library(DESeq)
read.csv('../DifferentialExpressionTools/RealDataset/final.csv')
str(x)
x<-read.csv('../DifferentialExpressionTools/count_table_merged.csv')
mean(x[,-1])
head(x)
colMeans(x)
colMeans(x[,-1])
hist(x[,2])
hist(x[,2],40)
hist(log(x[,2]),40)
hist(log(x[,3]),40)
require(ggplot2)
states = c("alabama","arizona","arkansas","california",
"colorado","connecticut","delaware","district of columbia",
"florida","georgia","idaho","illinois",
"indiana","iowa","kansas","kentucky",
"louisiana","maine","maryland","massachusetts",
"michigan","minnesota","mississippi","missouri",
"montana","nebraska","nevada","new hampshire",
"new jersey","new mexico","new york","north carolina",
"north dakota","ohio","oklahoma","oregon",
"pennsylvania","rhode island","south carolina","south dakota",
"tennessee","texas","utah","vermont",
"virginia","washington","west virginia","wisconsin",
"wyoming")
dataset <- data.frame(region=states,val=runif(49, 0,1))
us_state_map <- map_data('state')
map_data <- merge(us_state_map, dataset, by='region', all=T)
map_data <- map_data[order(map_data$order), ]
(qplot(long, lat, data=map_data, geom="polygon", group=group, fill=val)
+ theme_bw() + labs(x="", y="", fill="")
+ scale_fill_gradient(low='#EEEEEE', high='darkgreen')
+ theme(title="I was created using gplot2!",
legend.position="bottom", legend.direction="horizontal"))
head(map_data)
rm(list=la())
rm(list=ls())
library(ggplot2)
map_data()
?map_data()
map_data('state')
map('state')
map('us')
map('usa')
map('france')
map('world')
map('world2')
map.axes()
map.cities()
data(worldMapEnv)
worldMapEnv
data(world.cities)
head(world.cities)
world.cities=='Taiwan'
world.cities[world.cities=='Taiwan']
world.cities[world.cities[,2]=='Taiwan',]
map(world2,regions = 'asia')
map(world,regions = 'asia')
map('world2',regions = 'asia')
world2map<-map_data('world2')
head(world2map)
world2map[[region]]=='Taiwan'
world2map[['region']]=='Taiwan'
world2map[world2map[['region']]=='Taiwan',]
world2map[world2map[['region']]=='China',]
head(world2map)
world2map[world2map[['region']]=='Vatican',]
world2map[world2map[['region']]=='Italy',]
world2map[world2map[['region']]=='Hong kong',]
world2map[world2map[['region']]=='China',]
world2map[world2map[['sub region']]=='Taiwan',]
taiwanmap<-world2map[world2map[['subregion']]=='Taiwan',]
ggplot(taiwanmap)<-geom_polygon()
ggplot(taiwanmap)+geom_polygon()
ggplot(taiwanmap)+geom_polygon(aes(x=long, y=lat, group = group),colour="white", fill="grey10" ))
ggplot(taiwanmap)+geom_polygon(aes(x=long, y=lat, group = group),colour="white", fill="grey10" )
read.table('/Users/NeilWu/Dropbox/Friends/小貓.txt')
read.table('/Users/NeilWu/Dropbox/Friends/小貓.txt',fill = F)
read.table('/Users/NeilWu/Dropbox/Friends/小貓.txt',sep='')
read.table('/Users/NeilWu/Dropbox/Friends/小貓.txt',sep='     TT')
read.table('/Users/NeilWu/Dropbox/Friends/小貓.txt')
0.96^25
library(slidify)
library(devtools)
install_github('slidifyLibraries','ramnathv')
library(slidifyLibraries)
install.packages("rPython", repos = "http://www.datanalytics.com/R")
install.packages("rPython")
?sqrt
21^0.5
1/20
21^0.05
1.21^0.05
1.01^20
6.8*(5^0.5)
6.8/(5^0.5)
dir()
getwd()
grep('.*1024',dir())
dir_list<-dir()
dir_list[grep('.*1024',dir_list]
dir_list[grep('.*1024',dir_list)]
dir_list<-dir_list[grep('.*1024',dir_list)]
dir_list
?apply
HIV<-c(12.0,10.5,13.5,12.5,9.5,6.3,7.2)
mean(HIV)
median(H)
median(HIV)
sd(HIV)
system('rm -r output_score.txt')
source('~/Github/DifferentialExpressionTools/R scripts/Comparison/counttable_merge.R', echo=TRUE)
setwd('../DifferentialExpressionTools/Random_count/')
source('~/Github/DifferentialExpressionTools/R scripts/Comparison/counttable_merge.R', echo=TRUE)
rm(list=ls())
source('~/Github/DifferentialExpressionTools/R scripts/Comparison/counttable_merge.R', echo=TRUE)
View(count_table)
source('~/Github/DifferentialExpressionTools/R scripts/Comparison/Comparison.R', echo=TRUE)
setwd('../R scripts/')
source('~/Github/DifferentialExpressionTools/R scripts/Comparison/Comparison.R', echo=TRUE)
setwd('Comparison/')
source('~/Github/DifferentialExpressionTools/R scripts/Comparison/Comparison.R', echo=TRUE)
head(output_limma)
topCounts(output_limma)
topCounts(output_edgeR)
head(output_baySeq)
head(output_DE)
head(output_DE[order(output_DE$pval,decreasing = F),])
output_DE<-output_DE[order(output_DE$pval,decreasing = F),]
output_DEGSeq
head(output_DEGSeq)
head(output_DE)
head(output_edgeR)
head(output_edgeR$table)
head(output_edgeR$table[order(output_edgeR$table$PValue,decreasing = F),])
head(output_limma)
output_limma$p.value
head(output_limma$p.value)
head(output_limma$p.value[order(output_limma$p.value$groupB,decreasing = F),])
head(output_limma$p.value[order(output_limma$p.value$groupB,decreasing = F),])
output_limma$p.value$groupB
output_limma$p.value
output_limma$p.value[,2]
head(output_limma$p.value[order(output_limma$p.value[,2],decreasing = F),])
output_limma<-output_limma$p.value[order(output_limma$p.value[,2],decreasing = F),]
head(output_DEGSeq)
tail(output_DEGSeq)
sig_DEGseq<-output_DEGSeq[output_DEGSeq$p.value<0.05,]
tail(sig_DEGSeq)
tail(sig_DEGseq)
sig_DEGseq<-output_DEGSeq[output_DEGSeq$p.value<0.05 && !is.na(output_DEGSeq$p.value),]
tail(sig_DEGseq)
is.na(output_DEGSeq$p.value)
output_DEGSeq$p.value<0.05 && !is.na(output_DEGSeq$p.value)
output_DEGSeq$p.value<0.05 & !is.na(output_DEGSeq$p.value)
!is.na(output_DEGSeq$p.value),]
sig_DEGseq<-output_DEGSeq[output_DEGSeq$p.value<0.05 & !is.na(output_DEGSeq$p.value) ,]
tail(sig_DEGseq)
sig_DEseq<-output_DE[ output_DE$pval<0.05, ]
head(output_edgeR)
output_edgeR<-output_edgeR$table[order(output_edgeR$table$PValue,decreasing = F),]
head(output_edgeR)
sig_edgeR<-output_edgeR[ output_edgeR$PValue<0.05, ]
head(output_limma)
sig_limma<-output_limma[ output_limma[,2]<0.05, ]
as.data.frame(output_limma)
output_limma<-as.data.frame(output_limma)
sig_limma<-output_limma[ output_limma$groupB<0.05, ]
AnswerDE<-read.table('../../Random/allDElist.csv')
head(AnswerDE$V2)
AnswerDE<-read.table('../../Random/allDElist.csv',header = T)
head(AnswerDE$V2)
head(AnswerDE$X..DE.)
AnswerDE<-read.table('../../Random/allDElist.csv',header = T)
head(AnswerDE)
AnswerDE<-read.csv('../../Random/allDElist.csv')
head(AnswerDE)
AnswerDE$DE
is.na(AnswerDE$DE)
AnswerDE<-AnswerDE[!is.na(AnswerDE$DE),]
head(AnswerDE)
str(list_profile)
sig_all<-lapply(ls(pattern = 'sig_'), function(x) get(x))
lapply(sig_all,function(x) x %in% AnswerDE$gene_name)
lapply(sig_all,head)
sig_DEGseq$GeneNames %in% AnswerDE$gene_name
levels(AnswerDE$DE)
sig_DEGseq$GeneNames %in% AnswerDE$gene_name[ as.numeric(AnswerDE$DE)!=7 ]
sig_DEseq$id %in% AnswerDE$gene_name[ as.numeric(AnswerDE$DE)!=7 ]
row.names(sig_edgeR) %in% AnswerDE$gene_name[ as.numeric(AnswerDE$DE)!=7 ]
row.names(sig_limma) %in% AnswerDE$gene_name[ as.numeric(AnswerDE$DE)!=7 ]
sum(row.names(sig_limma) %in% AnswerDE$gene_name[ as.numeric(AnswerDE$DE)!=7 ])
sum(row.names(sig_limma) %in% AnswerDE$gene_name[ as.numeric(AnswerDE$DE)!=7 ])/length(row.names(sig_limma))
