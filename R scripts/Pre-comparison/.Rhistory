getwd()
read.csv('getdata-data-ss06hid.csv')
t<-read.csv('getdata-data-ss06hid.csv')
names(t)
strplit(names(t))
strsplit(names(t))
strsplit(names(t)split = 'wgtp')
strsplit(names(t),split = 'wgtp')
s<-read.csv('getdata-data-GDP.csv')
s$GDP
gsub(levels(s$GDP))
gsub(levels(s$GDP),',')
?gsub
gsub(levels(s$GDP),',','')
gsub(',','',levels(s$GDP),)
levels(s$GDP)<-gsub(',','',levels(s$GDP))
mean(as.numeric(as.character(s$GDP)))
names(s)
s$Country
s$Economy
as.character(s$Economy)
grep("^United",as.character(s$Economy))
as.character(s$Economy)
country_name<-as.character(s$Economy)
grep("^United*",country_name
)
country_name[99]
u<-read.csv('getdata-data-EDSTATS_Country.csv')
head(u)
merge(u,s,by.x='CountryCode',by.y=Country)
merge(u,s,by.x='CountryCode',by.y='Country')
merged<-merge(u,s,by.x='CountryCode',by.y='Country')
names(merged)
head(merged)
merged$Special.Notes
as.character(merged$Special.Notes)
special_notes<-as.character(merged$Special.Notes)
grep("^Fiscal year end",special_notes)
special_notes[grep("^Fiscal year end",special_notes)]
special_notes<-special_notes[grep("^Fiscal year end",special_notes)]
strsplit('Fiscal year end: ',special_notes)
strsplit(special_notes,'Fiscal year end: ')
sapply(strsplit(special_notes,'Fiscal year end: '),'[[')[2]
sapply(strsplit(special_notes,'Fiscal year end: '),'[['[2])
sapply(strsplit(special_notes,'Fiscal year end: '),'[[')
?'[['
sapply(strsplit(special_notes,'Fiscal year end: '),function(x) '[['[2])
sapply(strsplit(special_notes,'Fiscal year end: '),function(x) '[['[1])
sapply(strsplit(special_notes,'Fiscal year end: '),function(x) [[x]][2])
sapply(strsplit(special_notes,'Fiscal year end: ')
)
gsub('Fiscal year end: ','',special_notes)
special_notes<-gsub('Fiscal year end: ','',special_notes)
strsplit(' ',special_notes)
strsplit(special_notes,' ')
strsplit(special_notes,' ')[1]
strsplit(special_notes,' ')[1][1]
strsplit(special_notes,' ')[[1]]
strsplit(special_notes,' ')[[1]][1]
sapply(strsplit(special_notes,' '),'[[')
sapply(strsplit(special_notes,' '),FUN = '[[')
sapply(strsplit(special_notes,' '),print)
temp<-strsplit(special_notes,' ')
sapply(temp,'[[')
sapply(temp,print)
special_notes
grep('^June',special_notes)
sum(grep('^June',special_notes))
length(grep('^June',special_notes))
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
substr(sampleTimes,0,4)
year<-substr(sampleTimes,0,4)
sampleTimes
class(sampleTimes)
?Date
?weekdays
weekdays(sampleTimes)
weekdays(sampleTimes)=='Monday'
year=='2012'
year[year=='2012']
weekdays(sampleTimes[year=='2012'])
weekdays(sampleTimes[year=='2012'])=='Monday'
sum(weekdays(sampleTimes[year=='2012'])=='Monday')
special_notes
strsplit(special_notes,' ')
sapply(strsplit(special_notes,' '),function(x){x[1]})
?gsub
str_t
library(stringr)
str_trim(special_notes)
data(spam)
library(krenlab)
library(kernlab)
install.packages('kernlab')
library
library
library(kernlab)
data(spam)
30*.75
70*.47
x*.75+(1-x)*.47=30
x*.75+(1-x)*.47=30
0.47-0.28*x=0.3
x<-read.csv('../DifferentialExpressionTools/Random2/profiled_A1.pro')
head(x)
x<-read.table('../DifferentialExpressionTools/Random2/profiled_A1.pro',sep='\t')
head(x)
sum(x[,6])
str(x)
sum(as.numeric(x[,6]))
read.csv('../DifferentialExpressionTools/count_table_merged.csv')
library(DESeq)
read.csv('../DifferentialExpressionTools/RealDataset/final.csv')
str(x)
x<-read.csv('../DifferentialExpressionTools/count_table_merged.csv')
mean(x[,-1])
head(x)
colMeans(x)
colMeans(x[,-1])
hist(x[,2])
hist(x[,2],40)
hist(log(x[,2]),40)
hist(log(x[,3]),40)
require(ggplot2)
states = c("alabama","arizona","arkansas","california",
"colorado","connecticut","delaware","district of columbia",
"florida","georgia","idaho","illinois",
"indiana","iowa","kansas","kentucky",
"louisiana","maine","maryland","massachusetts",
"michigan","minnesota","mississippi","missouri",
"montana","nebraska","nevada","new hampshire",
"new jersey","new mexico","new york","north carolina",
"north dakota","ohio","oklahoma","oregon",
"pennsylvania","rhode island","south carolina","south dakota",
"tennessee","texas","utah","vermont",
"virginia","washington","west virginia","wisconsin",
"wyoming")
dataset <- data.frame(region=states,val=runif(49, 0,1))
us_state_map <- map_data('state')
map_data <- merge(us_state_map, dataset, by='region', all=T)
map_data <- map_data[order(map_data$order), ]
(qplot(long, lat, data=map_data, geom="polygon", group=group, fill=val)
+ theme_bw() + labs(x="", y="", fill="")
+ scale_fill_gradient(low='#EEEEEE', high='darkgreen')
+ theme(title="I was created using gplot2!",
legend.position="bottom", legend.direction="horizontal"))
head(map_data)
rm(list=la())
rm(list=ls())
library(ggplot2)
map_data()
?map_data()
map_data('state')
map('state')
map('us')
map('usa')
map('france')
map('world')
map('world2')
map.axes()
map.cities()
data(worldMapEnv)
worldMapEnv
data(world.cities)
head(world.cities)
world.cities=='Taiwan'
world.cities[world.cities=='Taiwan']
world.cities[world.cities[,2]=='Taiwan',]
map(world2,regions = 'asia')
map(world,regions = 'asia')
map('world2',regions = 'asia')
world2map<-map_data('world2')
head(world2map)
world2map[[region]]=='Taiwan'
world2map[['region']]=='Taiwan'
world2map[world2map[['region']]=='Taiwan',]
world2map[world2map[['region']]=='China',]
head(world2map)
world2map[world2map[['region']]=='Vatican',]
world2map[world2map[['region']]=='Italy',]
world2map[world2map[['region']]=='Hong kong',]
world2map[world2map[['region']]=='China',]
world2map[world2map[['sub region']]=='Taiwan',]
taiwanmap<-world2map[world2map[['subregion']]=='Taiwan',]
ggplot(taiwanmap)<-geom_polygon()
ggplot(taiwanmap)+geom_polygon()
ggplot(taiwanmap)+geom_polygon(aes(x=long, y=lat, group = group),colour="white", fill="grey10" ))
ggplot(taiwanmap)+geom_polygon(aes(x=long, y=lat, group = group),colour="white", fill="grey10" )
read.table('/Users/NeilWu/Dropbox/Friends/小貓.txt')
read.table('/Users/NeilWu/Dropbox/Friends/小貓.txt',fill = F)
read.table('/Users/NeilWu/Dropbox/Friends/小貓.txt',sep='')
read.table('/Users/NeilWu/Dropbox/Friends/小貓.txt',sep='     TT')
read.table('/Users/NeilWu/Dropbox/Friends/小貓.txt')
0.96^25
library(slidify)
library(devtools)
install_github('slidifyLibraries','ramnathv')
library(slidifyLibraries)
install.packages("rPython", repos = "http://www.datanalytics.com/R")
install.packages("rPython")
?sqrt
21^0.5
1/20
21^0.05
1.21^0.05
1.01^20
6.8*(5^0.5)
6.8/(5^0.5)
dir()
getwd()
grep('.*1024',dir())
dir_list<-dir()
dir_list[grep('.*1024',dir_list]
dir_list[grep('.*1024',dir_list)]
dir_list<-dir_list[grep('.*1024',dir_list)]
dir_list
?apply
HIV<-c(12.0,10.5,13.5,12.5,9.5,6.3,7.2)
mean(HIV)
median(H)
median(HIV)
sd(HIV)
read.table('../../Dropbox/NTU HW/Data Mining/D')
read.table('../../Dropbox/NTU HW/Data Mining/Homework3- libSVM/DM-HW3/income',sep=',')
income<-read.table('../../Dropbox/NTU HW/Data Mining/Homework3- libSVM/DM-HW3/income',sep=',')
str(income)
class(income$V15)
levels(income$V2)
levels(income[,2])
class(income[,2])
apply(income,2,function(x) class(x))
apply(income,2,function(x) class(get(x)))
apply(income,2,function(x) class(x))
lapply(income,function(x) class(x))
lapply(income,class)
lapply(income,function(x) if(class(x)=='factor){print(names(x))})
)
)
)
)
lapply(income,function(x) if(class(x)=='factor'){print(names(x))} )
lapply(income,function(x) if(class(x)=='factor'){print(colnames(x))} )
sapply(income,class)
sapply(income,class)=='factor'
head(income[,sapply(income,class)=='factor'])
str(income)
levels(income$V14)
levels(income$V15)
levels(income$V15)<-c('<=50K','<=50K','>50K','>50K')
levels(income$V15)
head(as.numeric(income[,sapply(income,class)=='factor']))
as.numeric(income[,sapply(income,class)=='factor'])
for(i in sapply(income,class)=='factor']){}
for(i in sapply(income,class)=='factor'){print(i)}
sapply(income,class)=='factor')
sapply(income,class)=='factor'
if(sapply(income,class)=='factor')
{print('dick')}
as.numeric(income[,sapply(income,class)=='factor'])
lapply(income[,sapply(income,class)=='factor'],as.numeric)
income[,sapply(income,class)=='factor']<-lapply(income[,sapply(income,class)=='factor'],as.numeric)
head(income)
a<-\
a<-/
a<- /
a<-
b
str(income)
factor(income$V15)
for(i in seq(1,length(income)))
{}
length(income)
paste0('1:',income[,1])
for(i in seq(1,length(income))){
income[,i]<-paste0(i,':',income[,i])
}
head(income)
write.table(income,'income_sorted',sep=' ',quote = F)
write.table(income,'income_sorted',sep=' ',quote = F,col.names = F)
library(qvalue)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
train<-createDataPartition(segmentationOriginal,p=0.6)
head(segmentationOriginal)
train<-createDataPartition(segmentationOriginal$Class,p=0.6)
head(train)
train<-createDataPartition(segmentationOriginal$Class,p=0.6,list = F)
head(train)
trainset<-segmentationOriginal[train,]
testset<-segmentationOriginal[-train,]
fit<-train(Class~.,mathod='rcart',data=trainset)
test<-data.frame(TotalIntench2=c(23000,50000,57000,0),FiberWidthCh1=c(10,10,8,8),VarIntenCh4=c(0,100,100,100),PerimStatusCh1=c(2,0,0,2))
predict(fit,test)
fit
predict(fit,newdata = test)
print(fit$finalModel)
fit<-train(Class~.,mathod='rpart',data=trainset)
print(fit$finalModel)
str(fit)
library(rattle)
fancyRpartPlot(fit$finalModel)
predict(fit,newdata = testset)
print(fit$finalModel)
fit<-train(Class~.,method='rpart',data=trainset)
print(fit$finalModel)
fancyRpartPlot(fit$finalModel)
predict(fit,newdata = test)
citation("limma")
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
install.packages(ElemStatLearn)
install.packages('ElemStatLearn')
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
fit<-train
library(caret)
fit<-train(y~.,data = vowel.train)
predict(fit,vowel.test)
confusionMatrix(predict(fit,vowel.test),vowel.test$y)
confusionMatrix(predict(fit,vowel.test),vowel.test$y)
length(vowel.test)
dim(vowel.test)
vowel.test$y
predicts<-predict(fit,vowel.test)
confusionMatrix(predicts,vowel.test$y)
ll
vowel.train$y<-factor(vowel.train$y)
fit<-train(y~.,data = vowel.train)
predicts<-predict(fit,vowel.test)
confusionMatrix(predicts,vowel.test$y)
vowel.test$y<-factor(vowel.test$y)
set.seed(33833)
fit<-train(y~.,data = vowel.train)
predicts<-predict(fit,vowel.test)
confusionMatrix(predicts,vowel.test$y)
library(AppliedPredictiveModeling)
data(concrete)
?concrete
getwd()
read.table('/Users/NeilWu/Desktop/GSE31827de')
temp<-read.table('/Users/NeilWu/Desktop/GSE31827de')
read.table('/Users/NeilWu/Desktop/Mus_musculus.GRCm38.78.gtf')
read.table('/Users/NeilWu/Desktop/Mus_musculus.GRCm38.78.gtf',sep='/t')
read.table('/Users/NeilWu/Desktop/Mus_musculus.GRCm38.78.gtf',sep='\t')
ref<-read.table('/Users/NeilWu/Desktop/Mus_musculus.GRCm38.78.gtf',sep='\t')
head(ref)
ref<-read.table('/Users/NeilWu/Desktop/Mus_musculus.GRCm38.78.gtf',sep=';')
ref<-read.table('/Users/NeilWu/Desktop/Mus_musculus.GRCm38.78.gtf',sep=';',fill=T)
head(ref)
read.table('/Users/NeilWu/Desktop/Mus_musculus.GRCm38.78.gtf',sep='NONO',fill=T)
read.table('/Users/NeilWu/Desktop/Mus_musculus.GRCm38.78.gtf',sep='NO',fill=T)
read.table('/Users/NeilWu/Desktop/Mus_musculus.GRCm38.78.gtf',sep='*',fill=T)
read.table('/Users/NeilWu/Desktop/Mus_musculus.GRCm38.78.gtf',sep=' ',fill=T)
head(ref)
sapply(head(ref),function(x) grepl(x,'gene_id'))
sapply(head(ref,4),function(x) grepl(x,'gene_id'))
sapply(head(ref,4),function(x) grepl('.*gene_id.*',x))
sapply(head(ref,4),function(x) x[grepl('.*gene_id.*',x)])
sapply(head(ref,4),function(x) x[grepl('.*gene_id.*',as.character(x))])
sapply(head(ref,4),function(x) grepl('.*gene_id.*',as.character(x)))
t<-sapply(head(ref,4),function(x) grepl('.*gene_id.*',as.character(x)))
head(ref,4)
head(ref,4)[t]
gene_id<-sapply(ref,function(x) grepl('.*gene_id.*',as.character(x)))
gene_name<-sapply(ref,function(x) grepl('.*gene_name.*',as.character(x)))
head(ref[gene_id])
head(ref[gene_name])
data.frame(gene_id=ref[gene_id],gene_name=ref[gene_name])
data<-data.frame(gene_id=ref[gene_id],gene_name=ref[gene_name])
head(data)
temp_id<-strsplit(ref[gene_id],' ')
head(temp_id)
temp_name<-strsplit(ref[gene_name],' ')
sapply(head(temp_id)),[2])
sapply(head(temp_id)),[[2])
sapply(head(temp_id)),[[2)
sapply(head(temp_id)),[[)
sapply(head(temp_id),[2])
sapply(head(temp_id),[2)
sapply(head(temp_id),[[])
sapply(head(temp_id),function(x) x[2])
temp_id_done<-sapply(temp_id,function(x) x[2])
temp_name_done<-sapply(temp_name,function(x) x[2])
head(temp_id_done)
head(temp_name_done)
temp_name<-strsplit(ref[gene_name],' ')
head(temp_name)
temp_name_done<-sapply(temp_name,function(x) x[3])
data<-data.frame(gene_id=temp_id_done,gene_name=temp_name_done)
head(data)
write.csv(data,'/Users/NeilWu/Desktop/Mouse_id_name.csv')
clear(gene_id)
clean(gene_id)
rm(gene_id)
rm(gene_name)
head(temp)
head(temp,20)
strsplit(temp,'_at')
strsplit(temp[1],'_at')
as.character(temp)
temp[1]
read.csv('/Users/NeilWu/Desktop/GSE31827de')
read.csv('/Users/NeilWu/Desktop/GSE31827de',sep=' ')
temp<-read.csv('/Users/NeilWu/Desktop/GSE31827de',sep=' ')
head(temp)
sapply(temp,function(x) strsplit(x,'_')[1])
sapply(temp,function(x) strsplit(x,'\_')[1])
sapply(temp,function(x) strsplit(x,'_at')[1])
temp<-read.csv('/Users/NeilWu/Desktop/GSE31827de',sep=' ',stringasfactor=F)
sapply(temp,function(x) strsplit(as.character(x),'_at')[1])
sapply(temp,function(x) strsplit(as.character(x),'_at'))
temp2<-sapply(temp,function(x) strsplit(as.character(x),'_at'))
head(temp2)
data.frame(temp2)
temp<-data.frame(temp2)
head(temp)
head(data)
merge(x=temp,y = data,by.x ='x',by.y='gene_id')
merge(x=temp,y = data,by.x =x,by.y=gene_id)
merge(x=temp,y = data,by.x ='x',by.y='gene_id')
typeof(data)
typeof(temp)
str(data)
str(temp)
temp$x
head(temp)
unlist(temp$x)
temp<-unlist(temp$x)
temp<-data.frame(temp)
str(temp)
merge(x=temp,y = data,by.x ='x',by.y='gene_id')
head(temp)
merge(x=temp,y = data,by.x ='temp',by.y='gene_id')
merged<-merge(x=temp,y = data,by.x ='temp',by.y='gene_id')
head(merged)
head(merged,10)
head(temp)
head(data)
length(data)
length(data$gene_id)
data[data$gene_id == 'ENSMUSG00000000154',]
duplicated(data)
sum(duplicated(data))
data[duplicated(data)]
data[duplicated(data),]
head(data[duplicated(data),])
head(data[duplicated(data),],40)
head(data[duplicated(data),],80)
data<-data[!duplicated(data),]
merged<-merge(x=temp,y = data,by.x ='temp',by.y='gene_id')
head(merged)
write.csv('/Users/NeilWu/Desktop/GSE31827de.csv',merged)
write.csv('/Users/NeilWu/Desktop/GSE31827de',merged)
write.csv('/Users/NeilWu/Desktop/GSE31827de',merged)
write.csv('/Users/NeilWu/Desktop/GSE31827de.csv',merged)
write.csv('/Users/NeilWu/Desktop/GSE31827de.csv',merged)
FN2<-read.csv('/Users/NeilWu/Dropbox/2-fold change (L12 over CTN).xls')
head(FN2)
library(xlsx)
??read.xls
library(gdata)
read.xls('/Users/NeilWu/Dropbox/2-fold change (L12 over CTN).xls')
FN2<-read.xls('/Users/NeilWu/Dropbox/2-fold change (L12 over CTN).xls')
head(FN2)
FN2_gn<-FN2$gene_name
head(FN2_gn)
head(temp2)
head(merged)
match(tolower(merged$gene_name),tolower(as.character(FN2_gn)))
!is.na(match(tolower(merged$gene_name),tolower(as.character(FN2_gn))))
match(tolower(merged$gene_name),tolower(as.character(FN2_gn)))
FN2_found<-merged$gene_name[!is.na(match(tolower(merged$gene_name),tolower(as.character(FN2_gn))))]
write.table(FN2_found,'/Users/NeilWu/Desktop/L12_over_match.txt')
write.table(FN2_found,'/Users/NeilWu/Desktop/L12_over_match.txt',row.names=F,quote=F)
write.table(FN2_found,'/Users/NeilWu/Desktop/L12_over_match.txt',row.names=F,quote=F,colnames=F)
write.table(FN2_found,'/Users/NeilWu/Desktop/L12_over_match.txt',row.names=F,quote=F,col.names=F)
FN2<-read.xls('/Users/NeilWu/Dropbox/2-fold change (M4 over CTN).xls')
head(FN2)
FN2_gn<-FN2$gene_name
FN2_found<-merged$gene_name[!is.na(match(tolower(merged$gene_name),tolower(as.character(FN2_gn))))]
head(FN2_found)
length(FN2_found)
write.table(FN2_found,'/Users/NeilWu/Desktop/M4_over_match.txt',row.names=F,quote=F,col.names=F)
FN2<-read.table('/Users/NeilWu/Dropbox/8-fold change (L12 over CTN).txt')
FN2<-read.table('/Users/NeilWu/Dropbox/8-fold change (L12 over CTN).txt',fill=T)
head(FN2)
FN2<-read.csv('/Users/NeilWu/Dropbox/8-fold change (L12 over CTN).txt',fill=T)
FN2<-read.table('/Users/NeilWu/Dropbox/8-fold change (L12 over CTN).txt',fill=T,header=T)
head(FN2)
FN2_gn<-FN2$gene_name
FN2_found<-merged$gene_name[!is.na(match(tolower(merged$gene_name),tolower(as.character(FN2_gn))))]
haed(FN2_found)
head(FN2_found)
length(FN2_found)
write.table(FN2_found,'/Users/NeilWu/Desktop/L12_over_match_fold8.txt',row.names=F,quote=F,col.names=F)
FN2<-read.table('/Users/NeilWu/Dropbox/8-fold change (M4 over CTN).txt',fill=T,header=T)
FN2_gn<-FN2$gene_name
FN2_found<-merged$gene_name[!is.na(match(tolower(merged$gene_name),tolower(as.character(FN2_gn))))]
write.table(FN2_found,'/Users/NeilWu/Desktop/M4_over_match_fold8.txt',row.names=F,quote=F,col.names=F)
?suppressPackageStartupMessages
suppressPackageStartupMessages
setwd('../DifferentialExpressionTools/R scripts/Pre-comparison/')
source('Profiler.R')
source('~/Github/DifferentialExpressionTools/R scripts/Pre-comparison/Profiler.R', echo=TRUE)
flux_profile_maker('1DE_14unDE','../../hg19_stranded.pro',replicate = 10)
